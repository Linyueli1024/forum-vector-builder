import pandas as pd
import json
import numpy as np
import faiss
import pymysql
from sqlalchemy import create_engine
from sentence_transformers import SentenceTransformer
from apscheduler.schedulers.background import BackgroundScheduler
import time

# === 1. åˆå§‹åŒ–æ¨¡å‹ ===
model = SentenceTransformer("all-MiniLM-L6-v2")

# === 2. MySQLè¿æ¥ä¿¡æ¯ ===
DB_URI = "mysql+pymysql://root:Lyl%40123456%21@8.208.33.213:3306/sofu"
engine = create_engine(DB_URI)

def extract_question_text(content_str):
    try:
        obj = json.loads(content_str)
        blocks = obj.get("blocks", [])
        for block in blocks:
            if block.get("type") == "text":
                return block.get("data", "").strip()
    except:
        return ""
    return ""

def update_index():
    print("â³ æ­£åœ¨æ‹‰å–æ•°æ®å¹¶æ›´æ–°ç´¢å¼•...")

    # === 3. è¯»å–æ•°æ®åº“ä¸­çš„æ•°æ® ===
    questions = pd.read_sql("SELECT * FROM questions", engine)
    questions.columns = ["id", "content", "bonus", "user_id", "created_at", "updated_at", "same_ques", "title"]
    questions["question_text"] = questions["content"].apply(extract_question_text)

    answers = pd.read_sql(
    "SELECT * FROM answers WHERE target_type = 'question'", engine
)[["id", "target_id", "user_id", "text", "created_at", "updated_at", "likes"]]

    # æŠŠ target_id é‡å‘½åä¸º question_id
    answers = answers.rename(columns={"target_id": "question_id"})

    # === 4. æ¯ä¸ªé—®é¢˜æ‹¼æ¥å‰2ä¸ªå›ç­” ===
    answer_group = answers.groupby("question_id")["text"].apply(
        lambda x: "\n".join([f"å›ç­”ï¼š{a.strip()}" for a in x.tolist()[:2]])
    ).reset_index()
    print(answer_group.columns.tolist())
    qa_df = pd.merge(questions[["id", "question_text"]], answer_group,
                     left_on="id", right_on="question_id", how="left")
    qa_df["qa_text"] = "é—®é¢˜ï¼š" + qa_df["question_text"] + "\n" + qa_df["text"].fillna("")
    qa_final = qa_df[["id", "qa_text"]].rename(columns={"id": "question_id"})

    # === 5. ç”Ÿæˆå‘é‡å¹¶æ„å»ºç´¢å¼• ===
    embeddings = model.encode(qa_final["qa_text"].tolist(), normalize_embeddings=True)
    index = faiss.IndexFlatIP(embeddings.shape[1])
    index.add(np.array(embeddings))

    # === 6. ä¿å­˜ç´¢å¼•å’Œæ˜ å°„æ–‡ä»¶ ===
    faiss.write_index(index, "qa_index.faiss")
    records = qa_final.to_dict(orient="records")
    with open("qa_mapping.json", "w", encoding="utf-8") as f:
        json.dump(records, f, ensure_ascii=False, indent=2)

    print("âœ… ç´¢å¼•å’Œæ˜ å°„æ›´æ–°å®Œæˆ")

# === å…ˆç«‹å³æ‰§è¡Œä¸€æ¬¡ï¼ˆé¦–æ¬¡å¯åŠ¨æ—¶ï¼‰===
update_index()
# === 7. å¯åŠ¨å®šæ—¶ä»»åŠ¡ï¼ˆæ¯5åˆ†é’Ÿï¼‰===
scheduler = BackgroundScheduler()
scheduler.add_job(update_index, 'interval', minutes=5)
scheduler.start()

print("ğŸ“¡ ç´¢å¼•æ›´æ–°æœåŠ¡å¯åŠ¨ä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢")

# ä¿æŒè¿›ç¨‹è¿è¡Œ
try:
    while True:
        time.sleep(60)
except (KeyboardInterrupt, SystemExit):
    scheduler.shutdown()
